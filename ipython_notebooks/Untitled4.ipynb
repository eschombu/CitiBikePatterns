{
 "metadata": {
  "name": "",
  "signature": "sha256:e26de5ac3d7af6d280494a41b24bb7918344279604801831644b60775b34e03b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import DataFrame, Series\n",
      "from sklearn.decomposition import PCA, FastICA, ProjectedGradientNMF\n",
      "from datetime import date, datetime, timedelta\n",
      "import time\n",
      "import pytz\n",
      "from pytz import timezone\n",
      "import calendar\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import copy\n",
      "import seaborn as sbs\n",
      "import sys\n",
      "sys.path.append('/home/vagrant/citibike')\n",
      "import map_figures as map\n",
      "\n",
      "\n",
      "## Load Citi Bike data\n",
      "CBmonths = np.append(np.append(np.append(np.ones((5,1))*2013, np.ones((12,1))*2014), np.ones((2,1))*2015), \\\n",
      "    np.array(range(8,13,1) + range(1,13,1) + range(1,3,1))).astype('int').reshape(2,19).T\n",
      "mo_strs = []\n",
      "for i in range(CBmonths.shape[0]):\n",
      "    mo_strs.append(date(CBmonths[i,0], CBmonths[i,1], 1))\n",
      "\n",
      "startDB_filename = \"/home/vagrant/citibike/hourlyDB_byStart_\" + mo_strs[0].strftime(\"%m-%Y\") + \\\n",
      "    \"_to_\" + mo_strs[-1].strftime(\"%m-%Y\") + \".csv.gz\"\n",
      "hourlyDF_bystart = pd.read_csv(startDB_filename, compression=\"gzip\", \\\n",
      "    index_col=['startbin', 'start station id', 'end station id'])\n",
      "\n",
      "endDB_filename = \"/home/vagrant/citibike/hourlyDB_byEnd_\" + mo_strs[0].strftime(\"%m-%Y\") + \\\n",
      "    \"_to_\" + mo_strs[-1].strftime(\"%m-%Y\") + \".csv.gz\"\n",
      "hourlyDF_byend = pd.read_csv(endDB_filename, compression=\"gzip\", \\\n",
      "    index_col=['stopbin', 'end station id', 'start station id'])\n",
      "\n",
      "## Load station info\n",
      "station_df = pd.read_csv(\"/home/vagrant/citibike/station_list.csv\", index_col=\"station id\")\n",
      "nstations = station_df.shape[0]\n",
      "\n",
      "## DataFrames for outflow and inflow of bikes into stations\n",
      "outflow = hourlyDF_bystart['total count'].sum(axis=0, level=['startbin', 'start station id'])\n",
      "outflow.index.names = ['timebin', 'station id']\n",
      "outflow = DataFrame({'outgoing': outflow})\n",
      "inflow = hourlyDF_byend['total count'].sum(axis=0, level=['stopbin', 'end station id'])\n",
      "inflow.index.names = ['timebin', 'station id']\n",
      "inflow = DataFrame({'incoming':inflow})\n",
      "\n",
      "## Merge outflow and inflow data into one DataFrame\n",
      "station_traffic_df = pd.merge(outflow, inflow, left_index=True, right_index=True, how='outer')\n",
      "station_traffic_df = station_traffic_df.fillna(0)\n",
      "\n",
      "## Matrix for decomposition algorithms\n",
      "station_traffic_matrix = station_traffic_df.unstack().fillna(0) # still type DataFrame\n",
      "\n",
      "## Add columns for datetime, hour, and weekday/holiday\n",
      "reftime = time.mktime(time.strptime('2000-01-01 00:00:00', '%Y-%m-%d %H:%M:%S'))\n",
      "binstart = time.mktime(time.strptime(date(CBmonths[0,0], CBmonths[0,1], 1 \\\n",
      "    ).strftime('%Y-%m-%d %H:%M:%S'), '%Y-%m-%d %H:%M:%S'))\n",
      "binend = time.mktime(time.strptime(date(CBmonths[-1,0], CBmonths[-1,1] + 1, 1 \\\n",
      "    ).strftime('%Y-%m-%d %H:%M:%S'), '%Y-%m-%d %H:%M:%S'))\n",
      "hourbins = np.linspace(binstart-reftime, binend-reftime, (binend-binstart)/3600 + 1)\n",
      "bins_datetime = [datetime.fromtimestamp(x+reftime) for x in hourbins]\n",
      "\n",
      "file = open('/home/vagrant/citibike/holidays.txt', 'r')\n",
      "holiday_strs = []\n",
      "for line in file:\n",
      "    holiday_strs.append(line.rstrip())\n",
      "file.close()\n",
      "file = open('/home/vagrant/citibike/holiday_related.txt', 'r')\n",
      "holidayRelated_strs = []\n",
      "for line in file:\n",
      "    holidayRelated_strs.append(line.rstrip())\n",
      "file.close()\n",
      "holidays = [datetime.strptime(x, '%Y-%m-%d').date() for x in holiday_strs]\n",
      "holidayRelated = [datetime.strptime(x, '%Y-%m-%d').date() for x in holidayRelated_strs]\n",
      "\n",
      "station_traffic_matrix['datetime'] = [bins_datetime[x] for x in station_traffic_matrix.index.values]\n",
      "station_traffic_matrix['hour'] = station_traffic_matrix['datetime'].map(lambda x: x.hour)\n",
      "station_traffic_matrix['WEEKDAY'] = station_traffic_matrix['datetime'].map(lambda x: calendar.weekday(x.year, x.month, x.day) in range(0,5))\n",
      "station_traffic_matrix['HOLIDAY'] = station_traffic_matrix['datetime'].map(lambda x: x.date() in holidays + holidayRelated)\n",
      "station_traffic_matrix['WEEKDAY'] = station_traffic_matrix['WEEKDAY'] & ~station_traffic_matrix['HOLIDAY']\n",
      "station_traffic_matrix['WEEKEND'] = ~station_traffic_matrix['WEEKDAY'] & ~station_traffic_matrix['HOLIDAY']\n",
      "\n",
      "station_traffic_imbal = station_traffic_matrix['outgoing'] - station_traffic_matrix['incoming']\n",
      "station_traffic_imbal['datetime'] = station_traffic_matrix['datetime']\n",
      "station_traffic_imbal['hour'] = station_traffic_matrix['hour']\n",
      "station_traffic_imbal[['WEEKDAY', 'WEEKEND', 'HOLIDAY']] = station_traffic_matrix[['WEEKDAY', 'WEEKEND', 'HOLIDAY']]\n",
      "\n",
      "AM_bools = station_traffic_matrix['hour'].isin(range(7,11)) & station_traffic_matrix['WEEKDAY']\n",
      "PM_bools = station_traffic_matrix['hour'].isin(range(16,20)) & station_traffic_matrix['WEEKDAY']\n",
      "\n",
      "## Typical daily time patterns\n",
      "wkday_hour_mean = station_traffic_matrix.ix[station_traffic_matrix['WEEKDAY'] \\\n",
      "    ].groupby('hour').mean()[['outgoing', 'incoming']]\n",
      "wkend_hour_mean = station_traffic_matrix.ix[station_traffic_matrix['WEEKEND'] \\\n",
      "    ].groupby('hour').mean()[['outgoing', 'incoming']]\n",
      "\n",
      "wkday_hour_imbal = station_traffic_imbal.ix[station_traffic_matrix['WEEKDAY'] \\\n",
      "    ].groupby('hour').mean()\n",
      "del wkday_hour_imbal['WEEKDAY'], wkday_hour_imbal['WEEKEND'], wkday_hour_imbal['HOLIDAY']\n",
      "wkday_hour_imbal.columns = pd.MultiIndex.from_tuples(zip(['out - in' for i in \\\n",
      "    range(len(wkday_hour_mean['outgoing'].columns))], wkday_hour_mean['outgoing'].columns), names=[None,'station id'])\n",
      "wkday_hour_mean = wkday_hour_mean.merge(wkday_hour_imbal, left_index=True, right_index=True)\n",
      "\n",
      "wkend_hour_imbal = station_traffic_imbal.ix[station_traffic_matrix['WEEKEND'] \\\n",
      "    ].groupby('hour').mean()\n",
      "del wkend_hour_imbal['WEEKDAY'], wkend_hour_imbal['WEEKEND'], wkend_hour_imbal['HOLIDAY']\n",
      "wkend_hour_imbal.columns = pd.MultiIndex.from_tuples(zip(['out - in' for i in \\\n",
      "    range(len(wkend_hour_mean['outgoing'].columns))], wkend_hour_mean['outgoing'].columns), names=[None,'station id'])\n",
      "wkend_hour_mean = wkend_hour_mean.merge(wkend_hour_imbal, left_index=True, right_index=True)\n",
      "\n",
      "## Variables for map plotting\n",
      "figdir = '/home/vagrant/citibike/figures/'\n",
      "map_img = plt.imread(fname='/home/vagrant/citibike/osm_screen2.png')\n",
      "map_corners_LatLong = np.loadtxt('/home/vagrant/citibike/osm_screen2_corners_LatLong.txt', delimiter=',')\n",
      "map_pixel_LatLong = map.gridCoords_fromCorners(map_corners_LatLong, map_img.shape[0:2])\n",
      "figsize1 = (8,8)\n",
      "figsize2 = (8,8)\n",
      "markersize1 = 13\n",
      "markersize2 = 7"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}